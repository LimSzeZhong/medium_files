{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bd67194",
   "metadata": {},
   "source": [
    "### Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbcfc928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f367af",
   "metadata": {},
   "source": [
    "### Initialize the Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fddfdeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use findspark.init() to locate spark on the system and import the library for you.\n",
    "# If you don't do this step, you might face an issue of python worker failed to connect.\n",
    "findspark.init()\n",
    "\n",
    "# Start the Spark session\n",
    "spark = SparkSession.builder.appName(\"ClassImbalanceHandling\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fee52f",
   "metadata": {},
   "source": [
    "## Create Mock Pyspark Dataset with Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41abf2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total of 500 Class B samples.\n",
      "          col1      col2        col3      col4       col5 class\n",
      "0 -1718.649877  0.898257  -39.836576 -0.198589   5.539138     A\n",
      "1  -121.041019 -0.444813    3.686693 -0.558107  -6.573311     A\n",
      "2  1038.512670  0.783736   42.352528  0.450083  13.525636     A\n",
      "3  -209.312628 -2.215415   36.416854  1.678712  12.133693     A\n",
      "4  -429.805510 -1.292846 -237.993497 -0.564347  16.672520     A\n"
     ]
    }
   ],
   "source": [
    "# Define the number of samples\n",
    "total_samples = 100000\n",
    "\n",
    "# Define the features (e.g., you can choose any distribution for feature values)\n",
    "# In this example, we use random values from normal distribution\n",
    "np.random.seed(0)\n",
    "feature1 = np.random.normal(0, 1000, total_samples)\n",
    "feature2 = np.random.normal(0, 1, total_samples)\n",
    "feature3 = np.random.normal(0, 100, total_samples)\n",
    "feature4 = np.random.normal(0, 1, total_samples)\n",
    "feature5 = np.random.normal(0, 10, total_samples)\n",
    "\n",
    "# Create the dataset\n",
    "data = {\n",
    "    \"col1\": feature1,\n",
    "    \"col2\": feature2,\n",
    "    \"col3\": feature3,\n",
    "    \"col4\": feature4,\n",
    "    \"col5\": feature5\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame with the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Introduce class imbalance by assigning one class more samples\n",
    "# In this example, Class A has the majority and Class B has the minority\n",
    "# You can adjust the imbalance ratio as needed\n",
    "imbalance_ratio = 0.005  # 0.5% Class B samples\n",
    "class_b_samples = int(total_samples * imbalance_ratio)\n",
    "total_class_b_samples = - class_b_samples\n",
    "print(f\"There are total of {-total_class_b_samples} Class B samples.\")\n",
    "\n",
    "# Add in the \"class\" column with the labels\n",
    "df['class'] = 'A'\n",
    "df.iloc[total_class_b_samples:,5] = 'B'\n",
    "\n",
    "# Shuffle the dataset to mix the classes (not that it makes a difference but just for demo.)\n",
    "df = df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "# Show the 1st 5 rows.\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef37104a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1     500\n",
      "col2     500\n",
      "col3     500\n",
      "col4     500\n",
      "col5     500\n",
      "class    500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check to see if there are the correct number of rows with Class B\n",
    "print(df.loc[df['class']=='B'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81850dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for the PySpark DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"Feature1\", DoubleType(), True),\n",
    "    StructField(\"Feature2\", DoubleType(), True),\n",
    "    StructField(\"Feature3\", DoubleType(), True),\n",
    "    StructField(\"Feature4\", DoubleType(), True),\n",
    "    StructField(\"Feature5\", DoubleType(), True),\n",
    "    StructField(\"Class\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Convert the pandas DataFrame to PySpark DataFrame\n",
    "pyspark_df = spark.createDataFrame(df, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd110327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-------------------+--------------------+-------------------+-----+\n",
      "|           Feature1|            Feature2|           Feature3|            Feature4|           Feature5|Class|\n",
      "+-------------------+--------------------+-------------------+--------------------+-------------------+-----+\n",
      "| -1718.649876612095|  0.8982566006303742| -39.83657612644435|-0.19858908539429249|  5.539138272731238|    A|\n",
      "|-121.04101922277877| -0.4448128444740752| 3.6866931235569558| -0.5581070764909885| -6.573310665724776|    A|\n",
      "|  1038.512669661264|  0.7837362000748797| 42.352528263407955| 0.45008269775923704| 13.525636175411687|    A|\n",
      "|-209.31262765761383|  -2.215414966767953| 36.416853544786235|  1.6787123778283846| 12.133693494115981|    A|\n",
      "|-429.80551004065086| -1.2928462486265264|-237.99349743855237| -0.5643467373641192|  16.67251969166381|    A|\n",
      "| -1330.663464004668|  0.7637053829834995| -78.96444127988173| -1.2669440573794475|   3.51228852908923|    A|\n",
      "|   847.291767134142| -1.0495009835441484| -91.45222096590821| -0.4846789203606238| -1.598706053879625|    A|\n",
      "| 460.41173892476763|-0.22573222263791606|  70.62936444276944|-0.49391143676494476| -2.879258462070054|    A|\n",
      "| -875.1621356272487|-0.38117237421972217| -77.99678247139528| 0.46983919162630267| 12.515767893931498|    A|\n",
      "| -627.3316004157076| -0.5549749215333662|-10.399219073136885|    0.89919015440135| 12.581688093472113|    A|\n",
      "| 1283.9845381228502|  -0.770592091483261| -68.94705087676064| -1.1602063056619414| -21.69550978113233|    A|\n",
      "|  -305.944577863589| -1.5923013186553838|  62.14700711604703|  0.5238622765978217| 16.103726606111632|    A|\n",
      "| -31.59523997266076| -0.7481769216697508| 1.4312485718023382| -0.8440012848666382|  6.344604577039053|    A|\n",
      "|  901.2888629053257|-0.16383099929719716| -30.55712458518012|   1.110898210243246| 18.657772747177628|    A|\n",
      "| 1032.6079164857313|  0.9795083910091734|-156.96507260752512|  -1.446482722684827|  4.307765130524367|    A|\n",
      "|   522.716870509614| -0.8729440902276315|   65.4561939568297| -1.2254965673696465| -12.30411445178711|    A|\n",
      "|  -3543.80320036059| -0.9763923854079711|  70.01052732965698|-0.02872537466436695|-3.8668618851579484|    A|\n",
      "|  1796.918522574928|    0.95010183298081|-18.030842662011683| -0.7287918190041712| 19.963286512370335|    A|\n",
      "| 1092.1074360600662| -0.2855768979216465| -78.50524422183368|-0.29798304555959565|  3.887619135686311|    A|\n",
      "| -40.76454042882965|  0.8111013856224446|  127.3220582267838|  -0.276534454376672| -3.863334839341741|    A|\n",
      "+-------------------+--------------------+-------------------+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the first few rows of the PySpark DataFrame\n",
    "pyspark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba9ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
